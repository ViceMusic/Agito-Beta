# Agito: Algorithmic Gene-Compression for Integrated Task Operations (AGITO)â€‹

ä¸ºä¸‹æ¸¸ä»»åŠ¡æä¾›çš„ç®—æ³•åŒ–åŸºå› å‹ç¼©æ–¹æ¡ˆã€‚

Adaptive Genomic-Informed Task-Optimizer (AGITO)â€‹

    å½“â€‹â€‹è§‰é†’çš„å‹ç¼©ä¹‹åŠ›â€‹â€‹å°†åŸºå› çš„æ··æ²Œè½¬åŒ–ä¸ºä¿¡æ¯çš„ç§©åºï¼Œç”Ÿç‰©å­¦çš„æ–°çºªå…ƒä¾¿éšÎ±åˆ°Î©çš„è½¨è¿¹é™ä¸´ã€‚
    â€”â€” æ­¤åæ—¢æ˜¯ç®—æ³•çš„å®£è¨€ï¼Œäº¦æ˜¯å‘è·¨è¶Šæ—¶ç©ºçš„éª‘å£«ç²¾ç¥çš„è‡´æ•¬ã€‚ ğŸ§¬âš¡ï¸

ç®—æ³•ç»„æˆï¼š

* ground
* storm
* flame

-----------------------------------------------------------------



## ğŸ“… å¼€å‘æ—¥å¿—

### notice ğŸ“Œ

----------------------------------------
### Date: 2025-7-5

#### âœ… The work of today

- normalizing all of variant and module name
- coding a draw script to reflect the trend in loss
- now, we finish the coding of embedding, encoder, and attention modules, and now we can get output consisted of tokens which are unorderable and have not space or time relationship.

#### ğŸ§  aspirations and thinkings

- we use attention mechanism replace max pooling approach to include "å¹³ç§»ä¸å˜æ€§"ï¼ˆIdk how to spell this wordï¼‰

#### ğŸ› question recording

- noep

#### ğŸ“ˆ æ˜æ—¥è®¡åˆ’ / TODO

- learn the graph network and study how to use "independent slot token"

```
Slot tokens	
Common in memory-based models	
"Each slot token stores distinct information"
```


----------------------------------------
### Date: 2025-7-11 21:00

#### âœ… The work of today

- we carefully review the method of getting global information in module "setAtten". And delete "MultiAttention".
- Then We executed a simple test showing that the decline speed of loss curve is worse then above test(use MultiAttention).

#### ğŸ§  aspirations and thinkings

- In my View, this question may be caused by two aspects: Firstly, the database set we used is compiled by ViceMusic(author), and is just used in programmer running fluently and checks if the error is in code. This dataset only contains rows in same label, by the way is not a reasonable dataset. Secondly, it is a simple meaning operator and linear map, no ability for coping with "slot-tokens", and may be just suitable for highly global tokens.

#### ğŸ› question recording

- The resuly shown in loss graphs reflects that removing the code of Multi-attention has put down the model's correction.
- However, Multi-attention will mix global information, and we has done it in pooling and fusing(above operation of MA). And I think that it is relative with the simple and unreasonable linear mapping......(in the end step of "Agito-ground").
- So we just "å°å°" this ability of Agito until we finish the next step of dealing with "slot-tokens" produced by ssm and pooling.

#### ğŸ“ˆ æ˜æ—¥è®¡åˆ’ / TODO

- nope
- study english
- study "Slot-to-Slot" graph structure auto modeling
- study contrastive study
- By the way, I find a interesting loss function called "é¦™å†œç†µè®¡ç®—ä¿¡æ¯å¯†åº¦"